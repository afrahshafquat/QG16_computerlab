---
author: "Jinhyun Ju"
output: html_document
---

Quantitative Genomics and Genetics 2016
======

Computer Lab 7
------

-- 7 April 2016

-- Author: Jin Hyun Ju (jj328@cornell.edu)

### 1. Logistic Regression

In logistic regression, the dependent variable y (in our case phenotype) is categorical instead of continuous. Specifically, we are going to implement logistic regression method that deals with binary phenotypes coded as 0 and 1. For example, in genome-wide association studies (GWAS) a healthy or normal control phenotype would be 0 and a disease phenotype (ex. diabetes, alzheimers, etc ...) would be 1. The goal is to identify genomic variations that increase the probability of belonging to the disease category. 

You might be wondering why we need this in the first place. So let's try to use linear regression for a binary phenotype and see what happens. 

```{r ,echo = FALSE,fig.show='hold',  fig.width=4, fig.height=4, fig.align='center'}
# This simulation is for demonstration purpose only, you should not simulate logistic regression results in this way. 
xa <- sample(c(-1,0,1), 100, replace = TRUE)
y <- 1* (xa * 0.7 + rnorm(100,0,1) > 0)

test_data <- data.frame("pheno" = y, "Xa" = xa)
linear_model <- lm(pheno ~ Xa, data=test_data)

plot(jitter(test_data$Xa, .3), jitter(test_data$pheno, .3), xlab = "Xa", ylab = "Y")
curve(predict(linear_model, data.frame(Xa=x), type="response"), add=TRUE, col = "blue") 

```

- What is the predicted value of Y for Xa = -1 in this case?

- If you plot out the residuals, how would it look like?

- What would be a good rule to deal with cases where the predicted values are greater or smaller than our sample space?

It becomes quite clear that we need a better alternative to linear regression for binary phenotypes. You can think of logistic regression as a transformation of the linear model to "fit" the binary phenotypes. 

```{r ,echo = FALSE,fig.show='hold',  fig.width=3, fig.height=1, fig.align='center'}
library(png)
library(grid)

img <- readPNG("./logistic_function.png")
grid.raster(img)
```

```{r ,echo = FALSE,fig.show='hold',  fig.width=3, fig.height=1, fig.align='center'}

img2 <- readPNG("./logistic_function2.png")
grid.raster(img2)

```

A simple visualization in R might give us a better idea of how the curve behaves:

```{r, echo = TRUE, fig.show='hold',  fig.width=4, fig.height=4, fig.align='center' }

x <- seq(from=-10,to=10,by = 0.1)
y <- 1 / (1+exp(-x))

plot(x,y, main = "logistic regression curve", type ="b")

```

Let's project the settings in our problem onto the above equation and clarify our goal. We have a given phenotype that takes either a value of 1 or 0, and two matrices for genotypes in the form of Xa(-1,0,1) coding and Xd(-1,1) coding. Just like in linear regression, the goal is to find the values for $\beta_{\mu}$, $\beta_a$ and $\beta_d$ for each genotype that best explain the relationship between the genotype and phenotype. If the relationship was error free and the genotype value directly predicts the phenotype, we would not need logistic regression (For example, if A2A2 indicates phenotype = 1 with 100% certainty). However, that is more than often not the case in real world genetics/genomics so we would have to "soft" model the relationship between genotypes and phenotypes by using probabilities, (In other words, A2A2 has a higher chance of having phenotype=1 than phenotype=0) and that is what the transformation given in the above equation is doing. So you might ask why do we need an algorithm to solve this problem if it is taking almost the exact same form as linear regression? The reason why we need an algorithm to calculate the maximum likelihood estimators for logistic regression is because there is no "closed-form" solution. In linear regression we had a "closed-form" solution which took the form of $MLE(\hat{\beta})=(XX^T)^{-1}X^TY$, but due to the transformation we are using in logistic regression we don't have such a simple solution in this case. So we are taking an "iterative" approach where the algorithm starts at a given point and keeps looking for a better solution in following steps until the better solution is almost identical to the solution from the previous step. 

Imagine that you are on a mountain in complete darkness and the only information that you have on hand is the current altitue which you can check every 5 minutes. The goal for you is to get to the highest point that you can reach and shoot up a flare to call for help. The optimal strategy for you will likely to pick a direction to walk for 5 minutes based on the angle of the ground you are standing on, and check your altitude after 5 minutes to confirm that you actually went uphill not downhill. When you are close to (or on) the top the altitude might not change much after walking for 5 minutes and that might be your best place for shotting a flare. This is kind of what is going on in the algorithm that we are implementing. 

### Exercise

1) Download the phenotype and genotype files from the class website and read them in.
   You should have 292 genotypes and 1 phenotype for 107 samples.
   
2) Note that the genotypes are already in Xa codings, and you only have to create the Xd matrix from it.

3) Use the template given below and try to fill in the code to make it a functional algorithm.

4) Plot a manhattan plot for the phenotype and look for significant peaks.

5) Your output should look something like this :

```{r, comment = NA, echo = FALSE,eval = FALSE, fig.align='center', fig.width=7,fig.height=4}
library(MASS)
library(ggplot2)
# QG lab 7
sim.logistic.dat <- function(Xa,Xd,beta){
  # create X matrix and beta vector

  X <- cbind(1,Xa,Xd)
  # Calculate E(Y|X)
  EY <- exp( X %*% beta) / (1+ exp(X %*% beta))
  
  # Calculate error
  epsilon <- apply(EY,1,function(a) rbinom(1,1,a) - a)
#  epsilon <- NULL
#  for (i in 1:n){
#    epsilon.i <- rbinom(1,1,EY[i]) - EY[i]
#    epsilon <- c(epsilon, epsilon.i)
#  }
  Y <- EY + epsilon
#  Y.j <- EY + epsilon.j
  
  return(Y)
}


logistic.IRLS<- function(Xa,Xd,Y =Y, beta.initial.vec = c(0,0,0), d.stop.th = 1e-6, it.max = 100) {

  #Create the X matrix
  X.mx <- cbind(1, Xa, Xd)
  
  N <- dim(X.mx)[1]
  	#check this matrix:
	#initialize the beta parameter vector at t=0
	beta.t <- beta.initial.vec
  
  # initialize deviance at d[t]
	dt<-0
	
	#initialize gamma
  # K is the part which goes into the exponent
	K<-X.mx %*% beta.t
	gamma_inv<-exp(K)/(1+exp(K))
	
	for(i in 1:it.max) {
		dpt1<-dt #store previous deviance
		
    # create empty matrix W
		W<-matrix(0,N,N)
    
    # Fill in the diagonal of W with appropriate values
		for(j in 1:N){
			W[j,j] <- gamma_inv[j] * (1-gamma_inv[j])
		}
    
    
		beta.t <- beta.t + ginv(t(X.mx)%*%W%*%X.mx)%*%t(X.mx)%*%(Y-gamma_inv)
		
		#update gamma since it's a function of beta
		K <- X.mx %*% beta.t
		gamma_inv <- exp(K)/(1+exp(K))

		#calculate new deviance
		dt <- 2*( sum(Y[Y==1]*log(Y[Y==1]/gamma_inv[Y==1])) + sum((1-Y[Y==0])*log((1-Y[Y==0])/(1-gamma_inv[Y==0]))) )
		
		absD <- abs(dt - dpt1)
		
		if(absD < d.stop.th) {
#			cat("Convergence at iteration:", i, "at threshold:", d.stop.th, "\n")
			logl<-sum(Y*log(gamma_inv)+(1-Y)*log(1-gamma_inv))
			return(list(beta.t,logl))
		}	
	}
#	cat("Convergence not reached after iteration:", i, "at threshold:", d.stop.th, "\n")
	return(list(beta.t= c(NA,NA,NA),logl=NA))
}



Y <- read.table("./QG16_Lab7_phenotypes.tsv", header = F,stringsAsFactors = F)
geno <- read.table("./QG16_Lab7_genotypes.tsv", header = T)

Y <- as.matrix(Y)
colnames(Y) <- NULL
Xa <- as.matrix(geno)
Xd <- 1 - 2*abs(Xa)



beta<-NULL
logl<-NULL
for(j in 1:dim(Xa)[2]){
	myList<-logistic.IRLS(Xa[,j],Xd[,j],Y=Y)
	beta<-cbind(beta,myList[[1]])
	logl<-c(logl,myList[[2]])
#	cat("Locus ",j,"'s beta values: ",myList[[1]],"\n")
}


# beta.mu for the null hypothesis
beta.mu.null<-mean(Y)

#gamma inverse for the null hypothesis (beta.a=beta.d=0, beta.mu=mean(Y))
gamma_inv_null<-exp(beta.mu.null)/(1+exp(beta.mu.null)) 

#likelihood ratio test statistic for every genotype
LRT<-2*logl-2*sum(Y*log(gamma_inv_null)+(1-Y)*log(1-gamma_inv_null)) 
pval <- pchisq(LRT, 2, lower.tail = F)

plot(-log10(pval), main = "P-values / Bonferroni cut-off")
abline(-log10(0.05/300),0,col="red")
```

6) You can also visualize the individual genotype effect by using the package ggplot2 with the option position = position_jitter(w = 0.1,h=0.1)

```{r, comment = NA, echo = FALSE,eval = FALSE, fig.align='center', fig.width=12,fig.height=5}

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

# Checking the effect 
i <- 180

plot.df <- data.frame( "Phenotype" = Y, "Xa" = Xa[,i], "Xd" = Xd[,i])
jitter.plot1 <- ggplot(plot.df, aes(x = Xa, y = Phenotype))+ geom_point(position = position_jitter(w = 0.1, h = 0.1)) + ggtitle("Xa vs Phenotype")
jitter.plot2 <- ggplot(plot.df, aes(x = Xd, y = Phenotype))+ geom_point(position = position_jitter(w = 0.1, h = 0.1)) + ggtitle("Xd vs Phenotype")

multiplot(plotlist = list(jitter.plot1,jitter.plot2), cols = 2)

```
